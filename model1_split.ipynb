{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a711da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7829a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47132b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7065abf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f27c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc66041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d504b2d8",
   "metadata": {},
   "source": [
    "# CHANGE THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddf1163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##MAKE SURE TO CHANGE THIS\n",
    "#best_model_path = \"models/fr_split_model.pth\"\n",
    "target_col = 'Enlarged Cardiomediastinum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14638654",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_root_dir, target_columns=None, transform=None,\n",
    "                 save_dir=None, use_saved_images=False):\n",
    "        self.data = dataframe\n",
    "        self.image_root_dir = image_root_dir\n",
    "        self.target_columns = target_columns\n",
    "        self.transform = transform\n",
    "        self.save_dir = save_dir\n",
    "        self.use_saved_images = use_saved_images\n",
    "\n",
    "        if self.save_dir:\n",
    "            os.makedirs(self.save_dir, exist_ok=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        \n",
    "        # Use index for the saved tensor filename\n",
    "        image_index = row['Unnamed: 0']\n",
    "        saved_image_path = os.path.join(self.save_dir, f\"{image_index}.pt\")\n",
    "\n",
    "        if self.use_saved_images:\n",
    "            if os.path.exists(saved_image_path):\n",
    "                image_tensor = torch.load(saved_image_path)\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Saved tensor not found: {saved_image_path}\")\n",
    "        else:\n",
    "            original_image_path = os.path.join(self.image_root_dir, row['Path'])\n",
    "            image = Image.open(original_image_path).convert(\"L\")\n",
    "            image_tensor = self.transform(image) if self.transform else transforms.ToTensor()(image)\n",
    "\n",
    "            if self.save_dir:\n",
    "                torch.save(image_tensor, saved_image_path)\n",
    "\n",
    "        if self.target_columns:\n",
    "            labels = pd.to_numeric(row[self.target_columns], errors='coerce').fillna(0).astype(float).values\n",
    "            labels = torch.tensor(labels, dtype=torch.float32)\n",
    "            return image_tensor, labels\n",
    "\n",
    "        return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b15e5076",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelResNet50(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_size = 512, dropout_rate=0.5):\n",
    "        super(MultiLabelResNet50, self).__init__()\n",
    "        \n",
    "        # Load pre-trained ResNet50\n",
    "        self.base_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # Modify the fully connected layer for multi-label classification\n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Linear(self.base_model.fc.in_features, hidden_size),  # New intermediate layer. ##512 --> 256\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),  # Dropout to prevent overfitting ##0.5 --> 0.6\n",
    "            nn.Linear(hidden_size, num_classes),  # Output layer\n",
    "            nn.Sigmoid()  # Sigmoid for multi-label classification (soften the data)\n",
    "            #nn.Tanh()  #This is between -1 and 1\n",
    "\n",
    "           # nn.Linear(self.base_model.fc.in_features, num_classes),\n",
    "           # nn.Sigmoid()  # Sigmoid activation for multi-label classification\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c22b365",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelResNet50_2(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MultiLabelResNet50_2, self).__init__()\n",
    "        \n",
    "        # Load pre-trained ResNet50\n",
    "        self.base_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # Modify the fully connected layer for multi-label classification\n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Linear(self.base_model.fc.in_features, 256),  # New intermediate layer. ##512 --> 256\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.6),  # Dropout to prevent overfitting ##0.5 --> 0.6\n",
    "            nn.Linear(256, num_classes),  # Output layer\n",
    "            nn.Sigmoid()  # Sigmoid for multi-label classification (soften the data)\n",
    "            #nn.Tanh()  #This is between -1 and 1\n",
    "\n",
    "           # nn.Linear(self.base_model.fc.in_features, num_classes),\n",
    "           # nn.Sigmoid()  # Sigmoid activation for multi-label classification\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "344d01b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoFindingRefiner(nn.Module):\n",
    "    def __init__(self, input_dim=6):  # 1 from image model + 5 pathology scores\n",
    "        super(NoFindingRefiner, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            #nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5), #was 0.5\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()  # Because your scores range from 0 to 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "374a7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoFindingRefiner2(nn.Module):\n",
    "    def __init__(self, input_dim=6):  # 1 from image model + 5 pathology scores\n",
    "        super(NoFindingRefiner2, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            #nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  #0.3 for 3\n",
    "            nn.Linear(128, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),  #0.3 for 3\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()  # Because your scores range from 0 to 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e7805e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mMultiLabelDenseNet121\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_classes, hidden_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m, dropout_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m(MultiLabelDenseNet121, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class MultiLabelDenseNet121(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_dim = 512, dropout_rate=0.5):\n",
    "        super(MultiLabelDenseNet121, self).__init__()\n",
    "\n",
    "        # Load pre-trained DenseNet-121\n",
    "        self.base_model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # Replace the classifier with a custom head\n",
    "        self.base_model.classifier = nn.Sequential(\n",
    "            nn.Linear(self.base_model.classifier.in_features, hidden_dim),  \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, num_classes),\n",
    "            nn.Tanh()  # Output values in [-1, 1] for each class\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3889a7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_root = '/central/groups/CS156b/2025/CodeMonkeys/input_images'\n",
    "image_root_dir = \"input_images/train_saved_tensors\"\n",
    "train_save_dir = os.path.join(image_root, 'train_saved_tensors')\n",
    "\n",
    "def get_filtered_df(col, num=None):\n",
    "    \n",
    "    #test_save_dir = os.path.join(image_root, 'test')\n",
    "    full_train_df = pd.read_csv('train2023.csv')\n",
    "    #print(len(full_train_df))\n",
    "    #filtered_train_df = full_train_df.iloc[:29692]\n",
    "    if num != None:\n",
    "        full_train_df = full_train_df.iloc[:num]\n",
    "\n",
    "    filtered_train_df = full_train_df.dropna(subset=[col]).copy()\n",
    "    filtered_train_df[col] = (filtered_train_df[col] + 1) / 2\n",
    "\n",
    "    df_front = filtered_train_df[filtered_train_df['Frontal/Lateral'] == 'Frontal'].copy()\n",
    "    df_lat = filtered_train_df[filtered_train_df['Frontal/Lateral'] == 'Lateral'].copy()\n",
    "\n",
    "    #filtered_train_df = filtered_train_df[filtered_train_df[col] != 0.5]  # Drop rows with 'Pleural_Effusion' == 0\n",
    "    return df_lat, df_front\n",
    "\n",
    "train_df_lat, train_df_front = get_filtered_df(target_col)\n",
    "#print(len(filtered_train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd7c6e8",
   "metadata": {},
   "source": [
    "# LATERAL VS FRONTAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5079f210",
   "metadata": {},
   "outputs": [],
   "source": [
    "##CHANGE THIS IF U WANT LAT VS FRONTAL\n",
    "best_model_path = \"models/ec_lat_model.pth\"\n",
    "filtered_train_df = train_df_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c33c3341",
   "metadata": {},
   "outputs": [],
   "source": [
    "##DONT GENERALLY WANT THIS\n",
    "# # Define desired number of samples per class\n",
    "sample_sizes = {\n",
    "    0.0: 10000,\n",
    "    0.5: 6000,\n",
    "    1.0: 10000\n",
    "}\n",
    "\n",
    "dfs = []\n",
    "for label, n_samples in sample_sizes.items():\n",
    "    class_df = filtered_train_df[filtered_train_df[target_col] == label]\n",
    "    # Sample with replacement if not enough data\n",
    "    sampled_df = class_df.sample(n=n_samples, replace=(n_samples > len(class_df)), random_state=42)\n",
    "    dfs.append(sampled_df)\n",
    "\n",
    "# Combine and shuffle\n",
    "balanced_df = pd.concat(dfs).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "filtered_train_df = balanced_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e851ad0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enlarged Cardiomediastinum\n",
      "0.0    5255\n",
      "0.5    2141\n",
      "1.0    1124\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_counts = filtered_train_df[target_col].value_counts()\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339e4823",
   "metadata": {},
   "outputs": [],
   "source": [
    "##DONT GENERALLY WANT THIS -- undersampling\n",
    "label_counts = filtered_train_df[target_col].value_counts()\n",
    "\n",
    "# Get majority class (should be 1.0)\n",
    "majority_class = label_counts.idxmax()\n",
    "\n",
    "# Separate the majority and minority classes\n",
    "majority_df = filtered_train_df[filtered_train_df[target_col] == majority_class]\n",
    "minority_df = filtered_train_df[filtered_train_df[target_col] != majority_class]\n",
    "\n",
    "# Randomly sample 10,000 from the majority class\n",
    "majority_sampled_df = majority_df.sample(n=10000, random_state=42)\n",
    "\n",
    "# Combine back\n",
    "balanced_df = pd.concat([majority_sampled_df, minority_df]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "filtered_train_df = balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "140c7362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define your target columns once\n",
    "target_columns = [target_col]\n",
    "\n",
    "# Step 1: Split the dataframe\n",
    "train_df, val_df = train_test_split(filtered_train_df, test_size=0.15, random_state=42)\n",
    "\n",
    "##MAY WANT TO GET RID OF THESE\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "# Step 2: Create training dataset\n",
    "train_dataset = CSVDataset(\n",
    "    dataframe=train_df, \n",
    "    image_root_dir=image_root, \n",
    "    target_columns=target_columns, \n",
    "    save_dir=train_save_dir, \n",
    "    use_saved_images=True\n",
    ")\n",
    "\n",
    "# Step 3: Create validation dataset\n",
    "val_dataset = CSVDataset(\n",
    "    dataframe=val_df, \n",
    "    image_root_dir=image_root, \n",
    "    target_columns=target_columns, \n",
    "    save_dir=train_save_dir, \n",
    "    use_saved_images=True\n",
    ")\n",
    "\n",
    "# Step 4: Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True) ##64 --> 32 --> 16 (prev)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efb31f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "##This is for oversampling\n",
    "fracture_labels = train_df[target_col].values\n",
    "label_map = {0.0: 0, 0.5: 1, 1.0: 2}\n",
    "mapped_labels = np.array([label_map[float(lbl)] for lbl in fracture_labels])\n",
    "\n",
    "class_counts = np.bincount(mapped_labels)\n",
    "weights = 1. / (class_counts + 1e-6)\n",
    "sample_weights = torch.tensor(weights[mapped_labels], dtype=torch.float)\n",
    "\n",
    "sampler = torch.utils.data.WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b304f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_base_layers_dn(model):\n",
    "    \"\"\"\n",
    "    Freeze initial layers of DenseNet-121 up to denseblock3.\n",
    "    \"\"\"\n",
    "    freeze = True\n",
    "    for name, child in model.base_model.features.named_children():\n",
    "        if name == 'denseblock2':\n",
    "            freeze = False\n",
    "        if freeze:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd975a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_base_layers(model, until_layer=6):\n",
    "    \"\"\"\n",
    "    Freeze layers of ResNet-50 up to a certain stage (e.g., until_layer=6 means keep layers 0-5 frozen).\n",
    "    \"\"\"\n",
    "    child_counter = 0\n",
    "    for child in model.base_model.children():\n",
    "        if child_counter < until_layer:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "        child_counter += 1\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9d81afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights for Enlarged Cardiomediastinum: {0: 1.0, 0.5: 0.6, 1: 1.0}\n"
     ]
    }
   ],
   "source": [
    "uncertain_weight_factor = 0.25\n",
    "class_weights = {}\n",
    "\n",
    "# Loop over each target column\n",
    "for col in target_columns:\n",
    "    # Count the occurrences of each class in the column\n",
    "    counts = filtered_train_df[col].value_counts()\n",
    "    total = len(filtered_train_df[col])\n",
    "    \n",
    "    # Calculate class weights using inverse frequency (you can also experiment with other strategies)\n",
    "    weights = {\n",
    "        0: total / (counts.get(0, 0) + 1),  # Add 1 to avoid division by zero\n",
    "        0.5: total / (counts.get(0.5, 0) + 1) * uncertain_weight_factor,\n",
    "        1: total / (counts.get(1, 0) + 1)\n",
    "    }\n",
    "    \n",
    "    # Store weights for each class\n",
    "    class_weights[col] = weights\n",
    "class_weights[target_col] = {0: 1.0, 0.5: 0.6, 1: 1.0}  ##GET RID OF THIS LINE IF DONT HAVE SAMPLER -- also 0.5\n",
    "# Example: Print out the weights for each class\n",
    "for col in target_columns:\n",
    "    print(f\"Class weights for {col}: {class_weights[col]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7faeaff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def masked_MSE_loss(output, target, class_weights):\\n    # Create a mask for non-NaN target values\\n    mask = ~torch.isnan(target)\\n    \\n    # Apply the MSE loss\\n    loss = criterion(output, target)\\n    \\n    # Loop through each class and apply the class weights\\n    for class_idx, col in enumerate(target_columns):\\n        # Get the class values for the current class\\n        class_values = target[:, class_idx]\\n        \\n        # Apply the class weights to each class value\\n        weight = torch.tensor([class_weights[col].get(x.item(), 1) for x in class_values], dtype=torch.float32, device=output.device)\\n        \\n        # Apply the weight to the loss (broadcast the weight to match the loss shape)\\n        loss = loss * mask  # Apply mask to exclude NaN targets\\n        loss[:, class_idx] *= weight  # Apply weight per class\\n    \\n    # Return mean loss for valid entries\\n    return loss.sum() / mask.sum()'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.MSELoss(reduction='none')\n",
    "\n",
    "def masked_MSE_loss(output, target, class_weights):\n",
    "    # Compute element-wise MSE\n",
    "    loss = criterion(output, target)  # shape: [batch_size, 1]\n",
    "\n",
    "    # Get weights per target value (assume target values are 0.0, 0.5, or 1.0)\n",
    "    weights = torch.tensor([class_weights.get(float(val.item()), 1.0) for val in target.squeeze()],\n",
    "                           dtype=torch.float32,\n",
    "                           device=output.device).unsqueeze(1)  # shape: [batch_size, 1]\n",
    "\n",
    "    # Apply weights to loss\n",
    "    weighted_loss = loss * weights\n",
    "\n",
    "    return weighted_loss.mean()\n",
    "\n",
    "'''def masked_MSE_loss(output, target, class_weights):\n",
    "    # Create a mask for non-NaN target values\n",
    "    mask = ~torch.isnan(target)\n",
    "    \n",
    "    # Apply the MSE loss\n",
    "    loss = criterion(output, target)\n",
    "    \n",
    "    # Loop through each class and apply the class weights\n",
    "    for class_idx, col in enumerate(target_columns):\n",
    "        # Get the class values for the current class\n",
    "        class_values = target[:, class_idx]\n",
    "        \n",
    "        # Apply the class weights to each class value\n",
    "        weight = torch.tensor([class_weights[col].get(x.item(), 1) for x in class_values], dtype=torch.float32, device=output.device)\n",
    "        \n",
    "        # Apply the weight to the loss (broadcast the weight to match the loss shape)\n",
    "        loss = loss * mask  # Apply mask to exclude NaN targets\n",
    "        loss[:, class_idx] *= weight  # Apply weight per class\n",
    "    \n",
    "    # Return mean loss for valid entries\n",
    "    return loss.sum() / mask.sum()'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06234449",
   "metadata": {},
   "source": [
    "## No Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e33376",
   "metadata": {},
   "outputs": [],
   "source": [
    "##NEW VERSION FOR FRACTURE\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "best_model_path = \"models/fr_front_model10.pth\"  ##Then get rid of this\n",
    "\n",
    "# Hyperparameters and model setup\n",
    "num_classes = 1  # Predicting 'Pleural Effusion'\n",
    "model = MultiLabelResNet50_2(num_classes=num_classes).to(device)\n",
    "model = freeze_base_layers(model, until_layer=2)  # Freeze layers\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-4)\n",
    "\n",
    "# Early stopping parameters\n",
    "early_stopping_patience = 3\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1)\n",
    "\n",
    "num_epochs = 15\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = masked_MSE_loss(outputs, labels, class_weights)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predicted_class = torch.where(outputs > 0.5, torch.tensor(1.0).to(device),\n",
    "                                      torch.where(outputs < -0.5, torch.tensor(-1.0).to(device), torch.tensor(0.0).to(device)))\n",
    "        correct += (predicted_class == labels).sum().item()\n",
    "        total += labels.numel()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    accuracy = correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = masked_MSE_loss(outputs, labels, class_weights)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            predicted_class = torch.where(\n",
    "                outputs < 0.25, torch.tensor(0.0).to(device),\n",
    "                torch.where(\n",
    "                    outputs < 0.75, torch.tensor(0.5).to(device),\n",
    "                    torch.tensor(1.0).to(device)\n",
    "                )\n",
    "            )\n",
    "\n",
    "            all_preds.append(predicted_class.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "            val_correct += (predicted_class == labels).sum().item()\n",
    "            val_total += labels.numel()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = val_correct / val_total\n",
    "\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early stopping check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        #print(\"✅ Saved new best model.\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "     #   print(f\"⏳ No improvement. Patience: {patience_counter}/{early_stopping_patience}\")\n",
    "\n",
    "    # Stop if patience exceeded\n",
    "    if patience_counter >= early_stopping_patience:\n",
    "        print(\"⛔ Early stopping triggered.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e96eb637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 11050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f41a043b5e0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/abaxter/.local/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sampler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSampler length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(sampler)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sampler' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset length: {len(train_dataset)}\")\n",
    "print(f\"Sampler length: {len(sampler)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5e614f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.1231, Accuracy: 0.5090\n",
      "Validation Loss: 0.2845, Validation Accuracy: 0.2613\n",
      "Epoch [2/30], Loss: 0.0825, Accuracy: 0.5866\n",
      "Validation Loss: 0.1901, Validation Accuracy: 0.3685\n",
      "Epoch [3/30], Loss: 0.0576, Accuracy: 0.6312\n",
      "Validation Loss: 0.1173, Validation Accuracy: 0.5955\n",
      "Epoch [4/30], Loss: 0.0438, Accuracy: 0.6490\n",
      "Validation Loss: 0.1172, Validation Accuracy: 0.5524\n",
      "Epoch [5/30], Loss: 0.0316, Accuracy: 0.6585\n",
      "Validation Loss: 0.1196, Validation Accuracy: 0.5368\n",
      "Epoch [6/30], Loss: 0.0309, Accuracy: 0.6531\n",
      "Validation Loss: 0.1248, Validation Accuracy: 0.5837\n",
      "Epoch [7/30], Loss: 0.0241, Accuracy: 0.6603\n",
      "Validation Loss: 0.1226, Validation Accuracy: 0.6142\n",
      "⛔ Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "# Hyperparameters and model setup\n",
    "#best_model_path = \"models/nf_front_model4.pth\"\n",
    "\n",
    "num_classes = 1  # Predicting 'Pleural Effusion'\n",
    "model = MultiLabelResNet50(num_classes=num_classes, hidden_size=128, dropout_rate=0.5).to(device) ##Was 256 for front\n",
    "#model = MultiLabelDenseNet121(num_classes=num_classes, hidden_dim=128, dropout_rate=0.5).to(device)\n",
    "model = freeze_base_layers(model, until_layer=2)  # Freeze layers\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "# Early stopping parameters\n",
    "early_stopping_patience = 3\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = masked_MSE_loss(outputs, labels, class_weights)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predicted_class = torch.where(outputs > 0.5, torch.tensor(1.0).to(device),\n",
    "                                      torch.where(outputs < -0.5, torch.tensor(-1.0).to(device), torch.tensor(0.0).to(device)))\n",
    "        correct += (predicted_class == labels).sum().item()\n",
    "        total += labels.numel()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    accuracy = correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = masked_MSE_loss(outputs, labels, class_weights)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            predicted_class = torch.where(\n",
    "                outputs < 0.25, torch.tensor(0.0).to(device),\n",
    "                torch.where(\n",
    "                    outputs < 0.75, torch.tensor(0.5).to(device),\n",
    "                    torch.tensor(1.0).to(device)\n",
    "                )\n",
    "            )\n",
    "\n",
    "            all_preds.append(predicted_class.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "            val_correct += (predicted_class == labels).sum().item()\n",
    "            val_total += labels.numel()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = val_correct / val_total\n",
    "\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early stopping check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        #print(\"✅ Saved new best model.\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "     #   print(f\"⏳ No improvement. Patience: {patience_counter}/{early_stopping_patience}\")\n",
    "\n",
    "    # Stop if patience exceeded\n",
    "    if patience_counter >= early_stopping_patience:\n",
    "        print(\"⛔ Early stopping triggered.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca91f9b",
   "metadata": {},
   "source": [
    "## With Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb555d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "input_dir = \"input_images/train_flipped\"\n",
    "output_dir = \"input_images/train_restored\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".pt\"):\n",
    "        tensor = torch.load(os.path.join(input_dir, filename))\n",
    "        restored_tensor = torch.flip(tensor, dims=[-1])  # flip along width\n",
    "        torch.save(restored_tensor, os.path.join(output_dir, filename))\n",
    "\n",
    "print(\"✅ Restored original training images to\", output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60abf554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch.optim as optim\n",
    "\n",
    "# Hyperparameter grid\n",
    "hidden_sizes = [256, 512]\n",
    "frozen_layers = [3, 5]\n",
    "learning_rates = [5e-4, 1e-4]\n",
    "\n",
    "# Results dictionary\n",
    "results = []\n",
    "\n",
    "# Model class (same as before, now parameterized)\n",
    "class MultiLabelResNet50(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_size):\n",
    "        super(MultiLabelResNet50, self).__init__()\n",
    "        self.base_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Linear(self.base_model.fc.in_features, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_size, num_classes),\n",
    "            nn.Tanh()  # Tanh outputs in range [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "# Freeze function\n",
    "def freeze_base_layers(model, until_layer):\n",
    "    child_counter = 0\n",
    "    for child in model.base_model.children():\n",
    "        if child_counter < until_layer:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "        child_counter += 1\n",
    "    return model\n",
    "\n",
    "# Grid search loop\n",
    "for hidden_size, freeze_until, lr in itertools.product(hidden_sizes, frozen_layers, learning_rates):\n",
    "    print(f\"Training model with hidden_size={hidden_size}, freeze_until={freeze_until}, lr={lr}\")\n",
    "    \n",
    "    # Init model and optimizer\n",
    "    model = MultiLabelResNet50(num_classes=1, hidden_size=hidden_size).to(device)\n",
    "    model = freeze_base_layers(model, until_layer=freeze_until)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training for a few epochs (e.g., 5)\n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = masked_MSE_loss(outputs, labels, class_weights)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = masked_MSE_loss(outputs, labels, class_weights)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            predicted = torch.where(outputs > 0, torch.tensor(1.0).to(device), torch.tensor(-1.0).to(device))\n",
    "            all_preds.append(predicted.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            val_total += labels.numel()\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    val_accuracy = val_correct / val_total\n",
    "    val_precision = precision_score(all_labels, all_preds, average='macro', zero_division=1)\n",
    "    val_recall = recall_score(all_labels, all_preds, average='macro', zero_division=1)\n",
    "    val_f1 = f1_score(all_labels, all_preds, average='macro', zero_division=1)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        'hidden_size': hidden_size,\n",
    "        'freeze_until': freeze_until,\n",
    "        'learning_rate': lr,\n",
    "        'val_loss': avg_val_loss,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'val_precision': val_precision,\n",
    "        'val_recall': val_recall,\n",
    "        'val_f1': val_f1\n",
    "    })\n",
    "\n",
    "# Sort and print top configs\n",
    "results.sort(key=lambda x: x['val_f1'], reverse=True)\n",
    "for r in results:\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf6aaa7",
   "metadata": {},
   "source": [
    "## Testing Model on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8477f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def evaluate_model_per_class(val_loader, device, model_path):\n",
    "    model = MultiLabelResNet50(num_classes=1).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = masked_MSE_loss(outputs, labels, class_weights)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            predicted_class = torch.where(outputs > 0, torch.tensor(1.0).to(device), torch.tensor(-1.0).to(device))\n",
    "\n",
    "            all_preds.append(predicted_class.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "            val_correct += (predicted_class == labels).sum().item()\n",
    "            val_total += labels.numel()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = val_correct / val_total\n",
    "\n",
    "    # Flatten for sklearn metrics\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    val_precision = precision_score(all_labels, all_preds, average='macro', zero_division=1)\n",
    "    val_recall = recall_score(all_labels, all_preds, average='macro', zero_division=1)\n",
    "    val_f1 = f1_score(all_labels, all_preds, average='macro', zero_division=1)\n",
    "\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"Validation Precision: {val_precision:.4f}, Validation Recall: {val_recall:.4f}, Validation F1: {val_f1:.4f}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "evaluate_model_per_class(val_loader, device, \"models/model_pe_epoch_10.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6b52fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def print_label_distribution(val_loader):\n",
    "    all_labels = []\n",
    "\n",
    "    for _, labels in val_loader:\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    all_labels = torch.cat(all_labels, dim=0).cpu().numpy()  # shape: (num_samples, num_classes)\n",
    "\n",
    "    num_classes = all_labels.shape[1]\n",
    "\n",
    "    print(\"Label distribution per class:\")\n",
    "    for i in range(num_classes):\n",
    "        unique, counts = np.unique(all_labels[:, i], return_counts=True)\n",
    "        dist = dict(zip(unique, counts))\n",
    "        print(f\"Class {i}: {dist}\")\n",
    "print_label_distribution(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76728039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "test_dataset = CSVDataset(\n",
    "    dataframe=df_first10rows_test, \n",
    "    image_root_dir=image_root, \n",
    "    target_columns=None, \n",
    "    transform=image_transforms,  # Pass the transform\n",
    "    save_dir=test_save_dir, \n",
    "    use_saved_images=False  # Set to True if you want to load tensors from CSV\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Iterate through batches\n",
    "for batch_idx, (images) in enumerate(test_loader):\n",
    "    print(f\"Batch {batch_idx + 1}\")\n",
    "    print(\"Images shape:\", images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc75356",
   "metadata": {},
   "source": [
    "## Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e435444",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MultiLabelResNet50' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_pel \u001b[38;5;241m=\u001b[39m \u001b[43mMultiLabelResNet50\u001b[49m(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      2\u001b[0m model_pel\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/pe_lat_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      3\u001b[0m model_pel\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MultiLabelResNet50' is not defined"
     ]
    }
   ],
   "source": [
    "model_pel = MultiLabelResNet50(num_classes=1).to(device)\n",
    "model_pel.load_state_dict(torch.load('models/pe_lat_model.pth'))\n",
    "model_pel.eval()\n",
    "\n",
    "model_pef = MultiLabelResNet50(num_classes=1).to(device)\n",
    "model_pef.load_state_dict(torch.load('models/pe_front_model.pth'))\n",
    "model_pef.eval()\n",
    "\n",
    "model_cml = MultiLabelResNet50_2(num_classes=1).to(device)\n",
    "model_cml.load_state_dict(torch.load('models/cm_lat_model2.pth'))\n",
    "model_cml.eval()\n",
    "\n",
    "model_cmf = MultiLabelResNet50(num_classes=1).to(device)\n",
    "model_cmf.load_state_dict(torch.load('models/cm_front_model.pth'))\n",
    "model_cmf.eval()\n",
    "\n",
    "model_lo = MultiLabelResNet50(num_classes=1, hidden_size=256).to(device)\n",
    "model_lo.load_state_dict(torch.load('amb_models/lo_partial/epoch_3.pth'))\n",
    "model_lo.eval()\n",
    "\n",
    "model_frl = MultiLabelResNet50_2(num_classes=1).to(device)\n",
    "model_frl.load_state_dict(torch.load('models/best_fr4_model.pth'))\n",
    "model_frl.eval()\n",
    "\n",
    "model_frf = MultiLabelResNet50_2(num_classes=1).to(device)\n",
    "model_frf.load_state_dict(torch.load('models/fr_front_model2.pth'))\n",
    "model_frf.eval()\n",
    "\n",
    "model_frt = MultiLabelResNet50_2(num_classes=1).to(device)\n",
    "model_frt.load_state_dict(torch.load('models/fr_lat_model5.pth'))\n",
    "model_frt.eval()\n",
    "\n",
    "model_nf = MultiLabelResNet50(num_classes=1, hidden_size=256).to(device)\n",
    "model_nf.load_state_dict(torch.load('amb_models/nf_partial/epoch_3.pth'))\n",
    "model_nf.eval()\n",
    "\n",
    "model_ec = MultiLabelResNet50(num_classes=1).to(device)\n",
    "model_ec.load_state_dict(torch.load('models/best_ec1_model.pth'))\n",
    "model_ec.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d925a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8f9e97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frontal:   0%|          | 0/19371 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frontal: 100%|██████████| 19371/19371 [09:31<00:00, 33.88it/s] \n",
      "Processing lateral: 100%|██████████| 3289/3289 [01:41<00:00, 32.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Predictions saved to 'test_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Directories\n",
    "dir_dict = {\n",
    "    \"frontal\": \"input_images/solution_frontal\",  ##NOTE THIS CHANGED TO SOLUTION IMAGES\n",
    "    \"lateral\": \"input_images/solution_lateral\"\n",
    "}\n",
    "\n",
    "# Column setup\n",
    "columns = [\"Id\", \"No Finding\", \"Enlarged Cardiomediastinum\", \"Cardiomegaly\", \"Lung Opacity\", \n",
    "           \"Pneumonia\", \"Pleural Effusion\", \"Pleural Other\", \"Fracture\", \"Support Devices\"]\n",
    "\n",
    "average_values = {\n",
    "    \"No Finding\": -0.734655,\n",
    "    \"Enlarged Cardiomediastinum\": -0.275805,\n",
    "    \"Cardiomegaly\": 0.190770,\n",
    "    \"Lung Opacity\": 0.836288,\n",
    "    \"Pneumonia\": 0.031183,\n",
    "    \"Pleural Other\": 0.521795,\n",
    "    \"Fracture\": 0.392374,\n",
    "    \"Support Devices\": 0.888289\n",
    "}\n",
    "\n",
    "batch_size = 64\n",
    "predictions = []\n",
    "\n",
    "# Loop over both frontal and lateral directories\n",
    "for view_type, test_dir in dir_dict.items():\n",
    "    model_pe = model_pef if view_type == \"frontal\" else model_pel\n",
    "    model_cm = model_cmf if view_type == \"frontal\" else model_cml\n",
    "    #model_ec = model_ecf if view_type == \"frontal\" else model_ecl\n",
    "   # model_nf = model_nff if view_type == \"frontal\" else model_nfl\n",
    "    file_list = [f for f in os.listdir(test_dir) if f.endswith(\".pt\")]\n",
    "    \n",
    "    batch = []\n",
    "    batch_filenames = []\n",
    "\n",
    "    for filename in tqdm(file_list, desc=f\"Processing {view_type}\"):\n",
    "        image_path = os.path.join(test_dir, filename)\n",
    "        image_tensor = torch.load(image_path).to(device)\n",
    "        batch.append(image_tensor)\n",
    "        batch_filenames.append(filename.split('.')[0])\n",
    "\n",
    "        if len(batch) == batch_size or filename == file_list[-1]:\n",
    "            input_batch = torch.stack(batch)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output_pe = model_pe(input_batch).cpu().numpy()\n",
    "                output_cm = model_cm(input_batch).cpu().numpy()\n",
    "                output_fr = model_fr(input_batch).cpu().numpy()\n",
    "                output_ec = model_ec(input_batch).cpu().numpy()\n",
    "                output_nf = model_nf(input_batch).cpu().numpy()\n",
    "                output_lo = model_lo(input_batch).cpu().numpy()\n",
    "\n",
    "\n",
    "            for i in range(len(batch)):\n",
    "                max_output = max(output_pe[i][0], output_cm[i][0], output_fr[i][0], output_ec[i][0], output_lo[i][0])\n",
    "                output_nf[i][0] = ((1 - max_output) + output_nf[i][0]) / 2\n",
    "\n",
    "                pe_score = output_pe[i][0] * 2 - 1\n",
    "                cm_score = output_cm[i][0] * 2 - 1\n",
    "                fr_score = output_fr[i][0] * 2 - 1\n",
    "                ec_score = output_ec[i][0] * 2 - 1\n",
    "                nf_score = output_nf[i][0] * 2 - 1\n",
    "                lo_score = output_lo[i][0] * 2 - 1\n",
    "\n",
    "                row = [batch_filenames[i]]\n",
    "                for col in columns[1:]:\n",
    "                    if col == \"Pleural Effusion\":\n",
    "                        row.append(pe_score)\n",
    "                    elif col == \"Cardiomegaly\":\n",
    "                        row.append(cm_score)\n",
    "                    elif col == \"Fracture\":\n",
    "                        row.append(fr_score)\n",
    "                    elif col == \"Enlarged Cardiomediastinum\":\n",
    "                        row.append(ec_score)\n",
    "                    elif col == \"No Finding\":\n",
    "                        row.append(nf_score)\n",
    "                    elif col == \"Lung Opacity\":\n",
    "                        row.append(lo_score)\n",
    "                    else:\n",
    "                        row.append(average_values.get(col, 0))\n",
    "\n",
    "                predictions.append(row)\n",
    "\n",
    "            batch = []\n",
    "            batch_filenames = []\n",
    "\n",
    "# Save all predictions\n",
    "df_predictions = pd.DataFrame(predictions, columns=columns)\n",
    "df_predictions = df_predictions.sort_values(by=\"Id\")\n",
    "df_predictions.to_csv('test_predictions.csv', index=False)\n",
    "\n",
    "print(\"✅ Predictions saved to 'test_predictions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38e01d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Predictions saved to 'test_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "#df_predictions['No Finding'] = df_predictions['No Finding'] * 2 - 1\n",
    "df_predictions = df_predictions.sort_values(by=\"Id\")\n",
    "df_predictions.to_csv('test_predictions.csv', index=False)\n",
    "\n",
    "print(\"✅ Predictions saved to 'test_predictions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c4aa366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3513232292094696\n"
     ]
    }
   ],
   "source": [
    "print(df_predictions['No Finding'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f856226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = pd.DataFrame(predictions, columns=columns)\n",
    "df_predictions = df_predictions.sort_values(by=\"Id\", ascending=True)\n",
    "df_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff492d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
