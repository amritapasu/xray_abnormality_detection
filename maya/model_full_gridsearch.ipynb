{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "10a10647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b8203a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "image_root = '/central/groups/CS156b/2025/CodeMonkeys/input_images'\n",
    "target_col = 'Lung Opacity'\n",
    "image_root_dir = \"input_images/train\"\n",
    "model_save_dir = 'maya_models/grid_search'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "end_df = 20000\n",
    "uncertain_weight_factor = 0.25\n",
    "neg_cutoff = 0.25\n",
    "pos_cutoff = 0.75\n",
    "\n",
    "num_epochs = 5  # Shorter for grid search\n",
    "freeze_until = 4\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63f3077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_root_dir, target_columns=None, transform=None, save_dir=None, use_saved_images=False):\n",
    "        self.data = dataframe\n",
    "        self.image_root_dir = image_root_dir\n",
    "        self.target_columns = target_columns\n",
    "        self.transform = transform\n",
    "        self.save_dir = save_dir\n",
    "        self.use_saved_images = use_saved_images\n",
    "        if self.save_dir:\n",
    "            os.makedirs(self.save_dir, exist_ok=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        image_index = row['Unnamed: 0']\n",
    "        saved_image_path = os.path.join(self.save_dir, f\"{image_index}.pt\")\n",
    "        if self.use_saved_images and os.path.exists(saved_image_path):\n",
    "            image_tensor = torch.load(saved_image_path)\n",
    "        else:\n",
    "            original_image_path = os.path.join(self.image_root_dir, row['Path'])\n",
    "            image = Image.open(original_image_path).convert(\"L\")\n",
    "            image_tensor = self.transform(image) if self.transform else transforms.ToTensor()(image)\n",
    "            if self.save_dir:\n",
    "                torch.save(image_tensor, saved_image_path)\n",
    "        labels = pd.to_numeric(row[self.target_columns], errors='coerce').fillna(0).astype(float).values\n",
    "        return image_tensor, torch.tensor(labels, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "718e1069",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelResNet50(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_size, dropout):  # <-- add dropout here\n",
    "        super().__init__()\n",
    "        self.base_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Linear(self.base_model.fc.in_features, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),  # <-- use dropout here\n",
    "            nn.Linear(hidden_size, num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "\n",
    "class MultiLabelDenseNet121(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_size, dropout):  # <-- add dropout here\n",
    "        super().__init__()\n",
    "        self.base_model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
    "        self.base_model.classifier = nn.Sequential(\n",
    "            nn.Linear(self.base_model.classifier.in_features, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),  # <-- use dropout here\n",
    "            nn.Linear(hidden_size, num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "\n",
    "def freeze_base_layers(model, until_layer=6):\n",
    "    child_counter = 0\n",
    "    for child in model.base_model.children():\n",
    "        if child_counter < until_layer:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "        child_counter += 1\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d95908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images with valid 'Lung Opacity' label: 10147\n"
     ]
    }
   ],
   "source": [
    "csv_path = '/central/groups/CS156b/2025/CodeMonkeys/train2023.csv'\n",
    "\n",
    "def get_filtered_df(col, num=None, csv_path='train2023.csv'):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if num:\n",
    "        df = df.iloc[:num]\n",
    "    df = df.dropna(subset=[col]).copy()\n",
    "    df[col] = (df[col] + 1) / 2\n",
    "    return df\n",
    "\n",
    "\n",
    "filtered_df = get_filtered_df(target_col, num=end_df, csv_path='/central/groups/CS156b/2025/CodeMonkeys/train2023.csv')\n",
    "print(f\"Total images with valid '{target_col}' label: {len(filtered_df)}\")\n",
    "\n",
    "target_columns = [target_col]\n",
    "\n",
    "train_df, val_df = train_test_split(filtered_df, test_size=0.15, random_state=42)\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
    "\n",
    "train_dataset = CSVDataset(train_df, image_root, target_columns, transform, save_dir=os.path.join(image_root, 'train'), use_saved_images=True)\n",
    "val_dataset = CSVDataset(val_df, image_root, target_columns, transform, save_dir=os.path.join(image_root, 'train'), use_saved_images=True)\n",
    "\n",
    "lo_labels = train_df[target_col].values\n",
    "label_map = {0.0: 0, 0.5: 1, 1.0: 2}\n",
    "mapped_labels = np.array([label_map[float(lbl)] for lbl in lo_labels])\n",
    "class_counts = np.bincount(mapped_labels)\n",
    "weights = 1. / (class_counts + 1e-6)\n",
    "sample_weights = torch.tensor(weights[mapped_labels], dtype=torch.float)\n",
    "sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class_weights = {target_col: {0: 1.0, 0.5: uncertain_weight_factor, 1: 1.0}}\n",
    "\n",
    "criterion = nn.MSELoss(reduction='none')\n",
    "\n",
    "def masked_MSE_loss(output, target, class_weights):\n",
    "    mask = ~torch.isnan(target)\n",
    "    loss = criterion(output, target)\n",
    "    for class_idx, col in enumerate(target_columns):\n",
    "        class_values = target[:, class_idx]\n",
    "        weight = torch.tensor([class_weights[col].get(x.item(), 1) for x in class_values], dtype=torch.float32, device=output.device)\n",
    "        loss = loss * mask\n",
    "        loss[:, class_idx] *= weight\n",
    "    return loss.sum() / mask.sum()\n",
    "\n",
    "def masked_MSE_loss_2(output, target, class_weights):\n",
    "    # output: (batch_size, 1)\n",
    "    # target: (batch_size, 1)\n",
    "    mask = ~torch.isnan(target)\n",
    "\n",
    "    # Basic unweighted MSE loss (elementwise)\n",
    "    loss = criterion(output, target)  # shape: (batch_size, 1)\n",
    "\n",
    "    # Get class values as floats: 0.0, 0.5, 1.0\n",
    "    class_vals = target.view(-1)\n",
    "    weights = torch.tensor(\n",
    "        [class_weights[target_columns[0]].get(x.item(), 1.0) for x in class_vals],\n",
    "        dtype=torch.float32, device=output.device\n",
    "    ).view(-1, 1)  # same shape as loss\n",
    "\n",
    "    # Apply weights and mask\n",
    "    weighted_loss = loss * weights * mask\n",
    "    print(\"Sample weights used:\", weights.view(-1)[:10])\n",
    "\n",
    "\n",
    "    return weighted_loss.sum() / mask.sum()\n",
    "\n",
    "\n",
    "#--------------------------------------------TRAINING------------------------------------------------------#\n",
    "\n",
    "def train_one_model(model_type, hidden_size, dropout, freeze_until, lr, weight_decay):\n",
    "    if model_type == \"resnet50\":\n",
    "        model = MultiLabelResNet50(num_classes=1, hidden_size=hidden_size, dropout=dropout).to(device)\n",
    "        model = freeze_base_layers(model, until_layer=freeze_until)\n",
    "    else:\n",
    "        model = MultiLabelDenseNet121(num_classes=1, hidden_size=hidden_size, dropout=dropout).to(device)\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Use only one loss for optimization\n",
    "            loss = masked_MSE_loss(outputs, labels, class_weights)\n",
    "            loss_2 = masked_MSE_loss_2(outputs, labels, class_weights)  # Just for tracking\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            preds = torch.where(outputs < neg_cutoff, 0.0,\n",
    "                    torch.where(outputs < pos_cutoff, 0.5, 1.0))\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.numel()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # ---- VALIDATION ----\n",
    "        model.eval()\n",
    "        val_loss, val_loss_2, val_correct, val_total = 0.0, 0.0, 0, 0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "\n",
    "                loss = masked_MSE_loss(outputs, labels, class_weights)\n",
    "                loss_2 = masked_MSE_loss_2(outputs, labels, class_weights)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                val_loss_2 += loss_2.item()\n",
    "\n",
    "                preds = torch.where(outputs < neg_cutoff, 0.0,\n",
    "                        torch.where(outputs < pos_cutoff, 0.5, 1.0))\n",
    "\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.numel()\n",
    "\n",
    "                all_preds.append(preds.cpu().numpy())\n",
    "                all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_loss_2 = val_loss_2 / len(val_loader)\n",
    "        val_accuracy = val_correct / val_total\n",
    "\n",
    "        print(f\"{model_type} H{hidden_size} D{dropout} F{freeze_until} LR{lr} WD{weight_decay} | Epoch {epoch+1}: \"\n",
    "              f\"ValLoss={avg_val_loss:.4f}, ValLoss2={avg_val_loss_2:.4f}, ValAcc={val_accuracy:.4f}\")\n",
    "\n",
    "        # ---- CONFUSION MATRIX ----\n",
    "        float_to_int = {0.0: 0, 0.5: 1, 1.0: 2}\n",
    "        pred_classes = np.array([float_to_int.get(float(v), -1) for v in np.concatenate(all_preds).flatten()])\n",
    "        true_classes = np.array([float_to_int.get(float(v), -1) for v in np.concatenate(all_labels).flatten()])\n",
    "\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        import seaborn as sns\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        cm = confusion_matrix(true_classes, pred_classes, labels=[0, 1, 2])\n",
    "        plt.figure(figsize=(5, 4))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=[\"Neg\", \"Unc\", \"Pos\"],\n",
    "                    yticklabels=[\"Neg\", \"Unc\", \"Pos\"])\n",
    "        plt.title(f'CM: {model_type}, H={hidden_size}, D={dropout}, Epoch {epoch+1}')\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        cm_filename = f\"cm_{model_type}_h{hidden_size}_d{dropout}_frz{freeze_until}_lr{lr}_wd{weight_decay}_epoch{epoch+1}.png\"\n",
    "        plt.savefig(os.path.join(model_save_dir, cm_filename))\n",
    "        plt.close()\n",
    "\n",
    "        # ---- EARLY STOPPING ----\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(),\n",
    "                       os.path.join(model_save_dir, f\"{model_type}_h{hidden_size}_lr{lr}_wd{weight_decay}_best.pth\"))\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= 2:\n",
    "                print(\"‚èπÔ∏è Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    return best_val_loss, val_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d13eb08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def grid_search():\n",
    "    model_types = ['resnet50', 'densenet121']\n",
    "    hidden_sizes = [256, 384, 512]\n",
    "    lrs = [1e-4, 5e-4]\n",
    "    wds = [1e-5, 1e-4]\n",
    "    frozen_layers = [3, 4, 5]\n",
    "    dropouts = [0.2, 0.4, 0.6]\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    best_config = None\n",
    "    results = []\n",
    "\n",
    "    # Unpack all 6 hyperparameters from grid\n",
    "    for m, h, lr, wd, fl, ds in product(model_types, hidden_sizes, lrs, wds, frozen_layers, dropouts):\n",
    "        print(f\"\\nüîç Training config: model={m}, hidden={h}, dropout={ds}, freeze_until={fl}, lr={lr}, wd={wd}\")\n",
    "        val_loss, val_acc = train_one_model(m, h, ds, fl, lr, wd)\n",
    "        results.append((m, h, ds, fl, lr, wd, val_loss, val_acc))\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_config = (m, h, ds, fl, lr, wd)\n",
    "\n",
    "    print(f\"\\n‚úÖ Best Config: {best_config} with ValLoss {best_loss:.4f}\")\n",
    "    pd.DataFrame(results, columns=[\"Model\", \"Hidden\", \"Dropout\", \"FreezeUntil\", \"LR\", \"WD\", \"ValLoss\", \"ValAcc\"]).to_csv(\n",
    "        os.path.join(model_save_dir, \"grid_results.csv\"), index=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b467d77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Training config: model=resnet50, hidden=256, dropout=0.2, freeze_until=3, lr=0.0001, wd=1e-05\n",
      "resnet50 H256 D0.2 F3 LR0.0001 WD1e-05 | Epoch 1: ValLoss=0.0809, ValLoss2=0.0809, ValAcc=0.7912\n",
      "resnet50 H256 D0.2 F3 LR0.0001 WD1e-05 | Epoch 2: ValLoss=0.0679, ValLoss2=0.0679, ValAcc=0.7873\n",
      "resnet50 H256 D0.2 F3 LR0.0001 WD1e-05 | Epoch 3: ValLoss=0.0693, ValLoss2=0.0693, ValAcc=0.8024\n",
      "resnet50 H256 D0.2 F3 LR0.0001 WD1e-05 | Epoch 4: ValLoss=0.0682, ValLoss2=0.0682, ValAcc=0.7991\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "\n",
      "üîç Training config: model=resnet50, hidden=256, dropout=0.4, freeze_until=3, lr=0.0001, wd=1e-05\n",
      "resnet50 H256 D0.4 F3 LR0.0001 WD1e-05 | Epoch 1: ValLoss=0.1020, ValLoss2=0.1020, ValAcc=0.7032\n",
      "resnet50 H256 D0.4 F3 LR0.0001 WD1e-05 | Epoch 2: ValLoss=0.0704, ValLoss2=0.0704, ValAcc=0.7965\n",
      "resnet50 H256 D0.4 F3 LR0.0001 WD1e-05 | Epoch 3: ValLoss=0.0868, ValLoss2=0.0868, ValAcc=0.7505\n",
      "resnet50 H256 D0.4 F3 LR0.0001 WD1e-05 | Epoch 4: ValLoss=0.0777, ValLoss2=0.0777, ValAcc=0.8056\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "\n",
      "üîç Training config: model=resnet50, hidden=256, dropout=0.6, freeze_until=3, lr=0.0001, wd=1e-05\n",
      "resnet50 H256 D0.6 F3 LR0.0001 WD1e-05 | Epoch 1: ValLoss=0.1040, ValLoss2=0.1040, ValAcc=0.6737\n",
      "resnet50 H256 D0.6 F3 LR0.0001 WD1e-05 | Epoch 2: ValLoss=0.1005, ValLoss2=0.1005, ValAcc=0.7216\n",
      "resnet50 H256 D0.6 F3 LR0.0001 WD1e-05 | Epoch 3: ValLoss=0.0829, ValLoss2=0.0829, ValAcc=0.7571\n",
      "resnet50 H256 D0.6 F3 LR0.0001 WD1e-05 | Epoch 4: ValLoss=0.0833, ValLoss2=0.0833, ValAcc=0.7452\n",
      "resnet50 H256 D0.6 F3 LR0.0001 WD1e-05 | Epoch 5: ValLoss=0.0870, ValLoss2=0.0870, ValAcc=0.7603\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "\n",
      "üîç Training config: model=resnet50, hidden=256, dropout=0.2, freeze_until=4, lr=0.0001, wd=1e-05\n",
      "resnet50 H256 D0.2 F4 LR0.0001 WD1e-05 | Epoch 1: ValLoss=0.1033, ValLoss2=0.1033, ValAcc=0.7124\n",
      "resnet50 H256 D0.2 F4 LR0.0001 WD1e-05 | Epoch 2: ValLoss=0.0884, ValLoss2=0.0884, ValAcc=0.7807\n",
      "resnet50 H256 D0.2 F4 LR0.0001 WD1e-05 | Epoch 3: ValLoss=0.0949, ValLoss2=0.0949, ValAcc=0.7577\n",
      "resnet50 H256 D0.2 F4 LR0.0001 WD1e-05 | Epoch 4: ValLoss=0.0826, ValLoss2=0.0826, ValAcc=0.7741\n",
      "resnet50 H256 D0.2 F4 LR0.0001 WD1e-05 | Epoch 5: ValLoss=0.0672, ValLoss2=0.0672, ValAcc=0.8043\n",
      "\n",
      "üîç Training config: model=resnet50, hidden=256, dropout=0.4, freeze_until=4, lr=0.0001, wd=1e-05\n",
      "resnet50 H256 D0.4 F4 LR0.0001 WD1e-05 | Epoch 1: ValLoss=0.1326, ValLoss2=0.1326, ValAcc=0.6218\n",
      "resnet50 H256 D0.4 F4 LR0.0001 WD1e-05 | Epoch 2: ValLoss=0.0707, ValLoss2=0.0707, ValAcc=0.7787\n",
      "resnet50 H256 D0.4 F4 LR0.0001 WD1e-05 | Epoch 3: ValLoss=0.0750, ValLoss2=0.0750, ValAcc=0.7951\n",
      "resnet50 H256 D0.4 F4 LR0.0001 WD1e-05 | Epoch 4: ValLoss=0.0818, ValLoss2=0.0818, ValAcc=0.7708\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "\n",
      "üîç Training config: model=resnet50, hidden=256, dropout=0.6, freeze_until=4, lr=0.0001, wd=1e-05\n",
      "resnet50 H256 D0.6 F4 LR0.0001 WD1e-05 | Epoch 1: ValLoss=0.1207, ValLoss2=0.1207, ValAcc=0.6494\n",
      "resnet50 H256 D0.6 F4 LR0.0001 WD1e-05 | Epoch 2: ValLoss=0.0767, ValLoss2=0.0767, ValAcc=0.7511\n",
      "resnet50 H256 D0.6 F4 LR0.0001 WD1e-05 | Epoch 3: ValLoss=0.0668, ValLoss2=0.0668, ValAcc=0.8135\n",
      "resnet50 H256 D0.6 F4 LR0.0001 WD1e-05 | Epoch 4: ValLoss=0.0670, ValLoss2=0.0670, ValAcc=0.7886\n",
      "resnet50 H256 D0.6 F4 LR0.0001 WD1e-05 | Epoch 5: ValLoss=0.0794, ValLoss2=0.0794, ValAcc=0.8024\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "\n",
      "üîç Training config: model=resnet50, hidden=256, dropout=0.2, freeze_until=5, lr=0.0001, wd=1e-05\n",
      "resnet50 H256 D0.2 F5 LR0.0001 WD1e-05 | Epoch 1: ValLoss=0.0913, ValLoss2=0.0913, ValAcc=0.7334\n",
      "resnet50 H256 D0.2 F5 LR0.0001 WD1e-05 | Epoch 2: ValLoss=0.0844, ValLoss2=0.0844, ValAcc=0.7525\n",
      "resnet50 H256 D0.2 F5 LR0.0001 WD1e-05 | Epoch 3: ValLoss=0.0712, ValLoss2=0.0712, ValAcc=0.8194\n",
      "resnet50 H256 D0.2 F5 LR0.0001 WD1e-05 | Epoch 4: ValLoss=0.0723, ValLoss2=0.0723, ValAcc=0.8056\n",
      "resnet50 H256 D0.2 F5 LR0.0001 WD1e-05 | Epoch 5: ValLoss=0.0686, ValLoss2=0.0686, ValAcc=0.8109\n",
      "\n",
      "üîç Training config: model=resnet50, hidden=256, dropout=0.4, freeze_until=5, lr=0.0001, wd=1e-05\n",
      "resnet50 H256 D0.4 F5 LR0.0001 WD1e-05 | Epoch 1: ValLoss=0.1148, ValLoss2=0.1148, ValAcc=0.6487\n",
      "resnet50 H256 D0.4 F5 LR0.0001 WD1e-05 | Epoch 2: ValLoss=0.0690, ValLoss2=0.0690, ValAcc=0.8030\n",
      "resnet50 H256 D0.4 F5 LR0.0001 WD1e-05 | Epoch 3: ValLoss=0.0873, ValLoss2=0.0873, ValAcc=0.7308\n",
      "resnet50 H256 D0.4 F5 LR0.0001 WD1e-05 | Epoch 4: ValLoss=0.0712, ValLoss2=0.0712, ValAcc=0.8076\n",
      "‚èπÔ∏è Early stopping triggered.\n",
      "\n",
      "üîç Training config: model=resnet50, hidden=256, dropout=0.6, freeze_until=5, lr=0.0001, wd=1e-05\n",
      "resnet50 H256 D0.6 F5 LR0.0001 WD1e-05 | Epoch 1: ValLoss=0.1135, ValLoss2=0.1135, ValAcc=0.6986\n",
      "resnet50 H256 D0.6 F5 LR0.0001 WD1e-05 | Epoch 2: ValLoss=0.0695, ValLoss2=0.0695, ValAcc=0.7984\n",
      "resnet50 H256 D0.6 F5 LR0.0001 WD1e-05 | Epoch 3: ValLoss=0.0752, ValLoss2=0.0752, ValAcc=0.7912\n",
      "resnet50 H256 D0.6 F5 LR0.0001 WD1e-05 | Epoch 4: ValLoss=0.0689, ValLoss2=0.0689, ValAcc=0.7925\n",
      "resnet50 H256 D0.6 F5 LR0.0001 WD1e-05 | Epoch 5: ValLoss=0.0665, ValLoss2=0.0665, ValAcc=0.7794\n",
      "\n",
      "üîç Training config: model=resnet50, hidden=256, dropout=0.2, freeze_until=3, lr=0.0001, wd=0.0001\n"
     ]
    }
   ],
   "source": [
    "grid_search()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
